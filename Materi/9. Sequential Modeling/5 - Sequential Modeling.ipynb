{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Modeling\n",
    "\n",
    "Sequential modeling adalah salah satu metode pemodelan yang dikhususkan untuk data-data yang memliki struktur berupa barisan. Beberapa data yang masuk kategori ini adalah:\n",
    "\n",
    "- Data runtun waktu (*time series*): *Stock market*, *speech*, *video*\n",
    "- Terurut: Teks, kode genetik\n",
    "\n",
    "Beberapa model sequential yang akan dipelajari adalah:\n",
    "\n",
    "- Hidden Markov Model (HMM)\n",
    "    - Conditional Random Field\n",
    "- Reccurent Neural Network (RNN)\n",
    "    - Long-Short Term Memory (LSTM)\n",
    "    - Gated Recurrent Unit (GRU)\n",
    "- Convolutional Neural Network (CNN)\n",
    "    - CNN-1D\n",
    "    \n",
    "Beberapa aplikasi dari model-model tersebut diantaranya:\n",
    "\n",
    "**Time Series Modeling**\n",
    "\n",
    "![Time Series](./images/timeseries.png)\n",
    "\n",
    "Sumber: https://towardsdatascience.com/an-overview-of-time-series-forecasting-models-a2fa7a358fcb\n",
    "\n",
    "**Part-of-Speech Tagging (POS-TAG)**\n",
    "\n",
    "![POS-TAG](./images/pos-title.jpg)\n",
    "\n",
    "Sumber: https://blog.aaronccwong.com/2019/building-a-bigram-hidden-markov-model-for-part-of-speech-tagging/\n",
    "\n",
    "**Named Entity Recognition (NER)**\n",
    "\n",
    "![NER](./images/ner.png)\n",
    "\n",
    "Sumber: http://www.europeana-newspapers.eu/named-entity-recognition-for-digitised-newspapers/\n",
    "\n",
    "**Natural Language Generator (NLG)**\n",
    "\n",
    "![NLG](./images/nlg.gif)\n",
    "\n",
    "Sumber: https://medium.com/human-on-tech/i-googled-for-you-natural-language-generation-35dd894d593d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Markov Model\n",
    "\n",
    "Hidden Markov Models (HMM) adalah salah satu model probabilistik berbasis graf yang memampukan kita untuk memprediksi sebarisan kejadian pada variabel yang tidak diketahui (*hidden*) dari sekumpulan variabel yang teramati (*observed variables*).\n",
    "\n",
    "![HMM](./images/hmm.png)\n",
    "\n",
    "Sumber: https://medium.com/@postsanjay/hidden-markov-models-simplified-c3f58728caab\n",
    "\n",
    "Secara matematis, HMM dapat dimodelkan sebagai berikut:\n",
    "\n",
    "![HMM-Math](./images/hmm-math.png)\n",
    "\n",
    "1. Observasi $o_{1}, ..., o_{T} \\in V$ dimana $V$ adalah ruang observasi\n",
    "2. *Hidden states* $s_{i}, ..., s_{T} \\in Q$ dimana $Q$ adalah ruang *hidden state*\n",
    "3. HMM memberikan nilai pronbabilitas pada tiap barisan $s_{1}, ..., s_{T}$, dimana:\n",
    "\n",
    "$$P(s_{1}, ..., s_{T}) = \\Pi^{T}_{t=1} P(s_{T}|s_{0}, ..., s_{t-1}) = \\Pi^{T}_{t=1} P(s_{t}|s_{<t})$$\n",
    "\n",
    "Dimana $s_{0}$ dikatakan sebagai *state* permulaan.\n",
    "\n",
    "4. Tiap observasi $o_{t}$ hanya bergantung pada *hidden state* $s_{t}$, atau secara matematis dapat didefinisikan sebagai:\n",
    "\n",
    "$$P(o_{t}|o_{<t}, s_{<t}) = P(o_{t}, s_{t})$$\n",
    "\n",
    "Sifat ini disebut sebagai asumsi independensi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varian HMM: Conditional Random Field (CRF)\n",
    "\n",
    "Conditional Random Field adalah pengembangan dari dua model Markov, yaitu HMM dan MEMM. Dengan menggabungkan kedua model sekuensial ini, CRF dapat diterapkan di berbagai kasus, mulai dari NER sampai deteksi objek.\n",
    "\n",
    "![CRF](./images/crf.jpeg)\n",
    "\n",
    "Sumber: https://medium.com/razorthink-ai/how-are-conditional-random-fields-applied-to-image-segmentation-ef511bf34a3f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network\n",
    "\n",
    "Recurrent neural network (RNN) adalah salah model sequential yang berbasis neural network.\n",
    "\n",
    "Berbeda dari arsitektur model MLP dan CNN, RNN secara struktur dapat dipakai untuk memodelkan data yang secara struktur memiliki pola sekuensial dengan cara menyimpan \"memori\" pada \"state\" sebelumnya. Istilah seperti *sekuensial* dan *states* menjadi penting untuk diketahui untuk mempelajari RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cara kerja RNN**\n",
    "\n",
    "- Data diubah menjadi vektor sehingga dapat diolah oleh model RNN\n",
    "\n",
    "![RNN-1](./images/rnn-1.gif)\n",
    "\n",
    "Sumber: https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n",
    "\n",
    "- Dalam prosesnya, tiap node akan memberikan *hidden state* ke node didepannya.\n",
    "\n",
    "![RNN-2](./images/rnn-2.gif)\n",
    "\n",
    "Sumber: https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n",
    "\n",
    "- Selanjutnya, *hidden state* dan input dihitung didalam node RNN sehingga diperoleh vektor yang membawa informasi dari input dan *hidden state* dari node sebelumnya. Vektor tersebut lalu diolah oleh fungsi aktivasi (dalam hal ini $\\tanh$) dan menghasilkan output berupa *hidden state* yang baru.\n",
    "\n",
    "![RNN-3](./images/rnn-3.gif)\n",
    "\n",
    "Sumber: https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n",
    "\n",
    "- Nilai dari vektor tersebut akan diteruskan melalui node-node lainnya\n",
    "\n",
    "![RNN-4](./images/rnn-4.gif)\n",
    "\n",
    "Sumber: https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varian RNN: Long-Short Term Memory (LSTM)\n",
    "\n",
    "Secara alur kerja, LSTM memiliki kemiripan dengan RNN, hanya saja memiliki banyak operasi yang terdapat di dalam nodenya.\n",
    "\n",
    "![RNN-5](./images/rnn-5.png)\n",
    "\n",
    "Sumber: https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n",
    "\n",
    "\n",
    "LSTM memiliki tiga bagian penting di dalamnya, yaitu forget gate, input gate dan cell gate.\n",
    "\n",
    "### Forget Gate\n",
    "\n",
    "![RNN-6](./images/rnn-6.gif)\n",
    "\n",
    "Sumber: https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n",
    "\n",
    "Forget gate berfungsi untuk menentukan informasi mana yang penting dan yang tidak. Hal ini diatur dengan cara memproses *hidden state* dan input melalui fungsi aktivasi sigmoid. Semakin dekat nilainya ke 0 maka semakin tidak penting informasi tersebut.\n",
    "\n",
    "### Input Gate\n",
    "\n",
    "![RNN-7](./images/rnn-7.gif)\n",
    "\n",
    "Sumber: https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n",
    "\n",
    "Input gate berfungsi untuk melakukan *updating* pada *cell state*. Pertama-tama, nilai *hidden state* dan nilai input dimasukkan ke dalam fungsi aktivasi sigmoid untuk menghitung seberapa penting informasi gabungan dari kedua nilai tersebut. Gabungan kedua nilai ini juga dihitung ke dalam fungsi $\\tanh$. Output dari kedua fungsi ini selanjutnya dikali untuk memberi bobot pada informasi yang diperoleh dari fungsi $\\tanh$.\n",
    "\n",
    "### Cell Gate\n",
    "\n",
    "![RNN-8](./images/rnn-8.gif)\n",
    "\n",
    "Sumber: https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n",
    "\n",
    "Cell gate berfungsi untuk menghitung *cell state* dari node lainnya sehingga diperoleh nilai *cell state* yang baru. Hal ini dilakukan dengan cara melakukan perkalian *pointwise* antara nilai *cell state* sebelumnya dengan nilai dari forget gate. Output dari perkalian *pointwise* ini akan dihitung kembali dengan nilai dari input gate dengan operasi penjumlahan *pointwise* sehingga diperoleh *cell state* yang baru.\n",
    "\n",
    "### Output Gate\n",
    "\n",
    "![RNN-9](./images/rnn-9.gif)\n",
    "\n",
    "Sumber: https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n",
    "\n",
    "Output gate berfungsi untuk menentukan *hidden state* yang baru. Hal ini dilakukan dengan cara memasukkan vektor gabungan nilai *hidden state* dari node sebelumnya dan nilai input ke dalam fungsi aktivasi sigmoid. Selanjutnya, vektor yang diperoleh dari fungsi aktivasi akan dihitung dengan *cell state* yang sudah ditransformasi sebelumnya oleh fungsi $\\tanh$ sehingga diperoleh *hidden state* yang baru untuk diteruskan ke node selanjutnya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Studi Kasus: LSTM untuk Pemodelan Time Series Univariate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Flatten\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('./dataset/airline/airline-passengers.csv', usecols=[1])\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(raw_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Windowing & Train-Test Splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_to_supervised(data, time_step=1):\n",
    "    df = pd.DataFrame(data)\n",
    "    columns = [df.shift(i) for i in range(1, time_step+1)]\n",
    "    columns.append(df)\n",
    "    df = pd.concat(columns, axis=1)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_for_model = timeseries_to_supervised(raw_data.values, 12).values\n",
    "\n",
    "data_for_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data_for_model[0:-120], data_for_model[-120:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reshaping trainX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = train[:, 0:-1], train[:, -1]\n",
    "X = X.reshape(X.shape[0], 1, X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Fitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# inisiasi model\n",
    "model = Sequential()\n",
    "\n",
    "# menambah layer LSTM\n",
    "model.add(LSTM(units=1, batch_input_shape=(1, X.shape[1], X.shape[2]), stateful=True))\n",
    "\n",
    "# layer output\n",
    "model.add(Dense(1))\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "plot_model(model, to_file='multiple_inputs.png', dpi=300)\n",
    "Image(retina=True, filename='multiple_inputs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3000):\n",
    "    model.fit(X, y, epochs=1, batch_size=1, verbose=1, shuffle=False)\n",
    "    model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testX = testX.reshape(testX.shape[0], 1, testX.shape[1])\n",
    "\n",
    "testX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in range(len(X)-1):\n",
    "    prediksi = model.predict(X[0:-1][i].reshape(1,1,12), batch_size=1)\n",
    "    y_pred.append(prediksi.tolist()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "trainPredictPlot = np.empty_like(raw_data)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[time_step:len(trainPredict)+time_step, :] = trainPredict\n",
    "\n",
    "testPredictPlot = np.empty_like(raw_data)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(time_step*2)+1:len(raw_data)-1, :] = testPredict\n",
    "\n",
    "plt.plot(raw_data)\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Latihan**\n",
    "\n",
    "1. Lakukan proses differencing pada data sebelum dijadikan data latih untuk menghilangkan efek trend dan seasonal dengan fungsi dibawah, lalu lanjutkan preprocessing lainnya seperti \n",
    "2. Optimalkan model LSTM diatas dengan cara menambah layer, mengganti fungsi optimasi, menambah jumlah epoch dan hyperparameter lainnya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fungsi differencing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# untuk raw_data\n",
    "def difference(raw_data, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(raw_data)):\n",
    "        value = raw_data[i] - raw_data[i - interval]\n",
    "        diff.append(value)\n",
    "    return pd.Series(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# untuk kelas target\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "    return yhat + history[-interval]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fungsi Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# inisiasi MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# fit pada trainX\n",
    "scaler = scaler.fit(trainX)\n",
    "\n",
    "# transform trainX menjadi train_X_scaled\n",
    "trainX = trainX.reshape(trainX.shape[0], trainX.shape[1])\n",
    "train_X_scaled = scaler.transform(trainX)\n",
    "\n",
    "# transform testX menjadi test_X_scaled\n",
    "testX = testX.reshape(testX.shape[0], testX.shape[1])\n",
    "test_X_scaled = scaler.transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_scale(scaler, X, value):\n",
    "    new_row = [x for x in X] + [value]\n",
    "    array = numpy.array(new_row)\n",
    "    array = array.reshape(1, len(array))\n",
    "    inverted = scaler.inverse_transform(array)\n",
    "    return inverted[0, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contoh**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hasil = difference(raw_data.Passengers,1)\n",
    "hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hasil = pd.DataFrame(hasil).values\n",
    "hasil = hasil.astype('float32')\n",
    "hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
