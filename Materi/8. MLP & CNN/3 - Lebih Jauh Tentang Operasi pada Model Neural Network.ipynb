{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lebih Jauh tentang Aplikasi Model Neural Network\n",
    "\n",
    "![Meme Keras](./images/meme_keras.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Approximation Theorem\n",
    "\n",
    "\n",
    "Bunyi dari *Universal Approximation Theorem* adalah sebagai berikut:\n",
    "\n",
    "> \"Sebuah jaringan propagasi dengan hanya *hidden layer* tunggal yang memuat berhingga neuron dapat melakukan aproksimasi (pendekatan) untuk tiap fungsi kontinu dalam subset $\\mathbb{R}^{n}$ ...\"\n",
    "\n",
    "**Beberapa fitur yang membuat MLP begitu baik dalam menyelesaikan masalah**:\n",
    "\n",
    "- Stochastic Gradient Descent\n",
    "- Automatic feature learning\n",
    "- Klasifikasi multiclass\n",
    "- Model parametrik\n",
    "\n",
    "**Beberapa kekurangan**:\n",
    "\n",
    "- Input harus berupa bilangan real\n",
    "- Cenderung *overfitting*\n",
    "- Terlalu banyak *hyperparameter* yang harus dioptimalkan\n",
    "    - jumlah layer\n",
    "    - fungsi aktivasi\n",
    "    - konektivitas\n",
    "    - inisiasi bobot\n",
    "    - loss function yang digunakan\n",
    "    - metode regularisasi yang digunakan\n",
    "    - dll\n",
    "- **Black box** *as same as* **black magic**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contoh Kasus: MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./dataset/digit_recognizer/train.csv\")\n",
    "test_data = pd.read_csv(\"./dataset/digit_recognizer/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# informasi terkait tipe dan dimensi data training\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# informasi terkait tipe dan dimensi data test\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cek data yang hilang pada data training\n",
    "train_data.isna().sum().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cek data yang hilang pada data test\n",
    "test_data.isna().sum().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buat variabel untuk menyimpan kelas target\n",
    "y_train = train_data['label']\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buang kolom 'label' pada train data\n",
    "train_data = train_data.drop(columns='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cek distribusi kelas target\n",
    "y_train.value_counts().plot.barh();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grayscaling\n",
    "train_data = train_data/255\n",
    "\n",
    "test_data = test_data/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping\n",
    "train_data = train_data.values\n",
    "\n",
    "test_data = test_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lihat gambar pada dataset\n",
    "plt.imshow(train_data[2].reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train).values\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(train_data, y_train, test_size = 0.1, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisiasi model sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(input_dim=784, units=128, kernel_initializer='uniform', activation='sigmoid'))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_prediksi = model.predict_classes(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_sebenarnya = np.argmax(Y_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(np.argmax(Y_val, axis=1), hasil_prediksi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_val_sebenarnya, hasil_prediksi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Latihan**\n",
    "\n",
    "Coba buat model dengan tiga, empat sampai lima hidden layer. Amati apakah hasilnya semakin akurat atau tidak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contoh Kasus: Time Series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./dataset/airline/airline-passengers.csv', usecols=[1], engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.values\n",
    "dataset = dataset.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dataset) * 0.80)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = 1\n",
    "trainX, trainY = create_dataset(train, time_step)\n",
    "testX, testY = create_dataset(test, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim=time_step, units=8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredictPlot = np.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[time_step:len(trainPredict)+time_step, :] = trainPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(dataset)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(time_step*2)+1:len(dataset)-1, :] = testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot baseline and predictions\n",
    "plt.plot(dataset)\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Latihan**\n",
    "\n",
    "1. Hasilnya tidak masuk akal. Coba ganti kernel_initializer dari 'zeros' ke 'uniform' dan amati efeknya.\n",
    "2. Gunakan time_step dari 2 ,3, 4, dan 5 dan amati mana yang menghasilkan output paling akurat\n",
    "3. Gunakan layer dari 2, 3, dan 4 layer dan amati mana yang hasilnya paling akurat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dari MLP menuju Deep Learning\n",
    "\n",
    "Beberapa kendala dalam pemrosesan data:\n",
    "\n",
    "- Data berukuran sangat besar\n",
    "    - Jumlah baris data yang diolah\n",
    "    - Jumlah fitur yang digunakan\n",
    "    - Data bersifat kompleks (misalnya gambar, video, teks)\n",
    "\n",
    "![Tantangan](./images/challenges.jpeg)\n",
    "\n",
    "Sumber: http://cs231n.github.io/classification/\n",
    "\n",
    "**Segmentasi Gambar**\n",
    "\n",
    "![Bola hijau](./images/clutter.jpg)\n",
    "\n",
    "Sumber: https://zbigatron.com/why-is-image-processing-so-hard/\n",
    "\n",
    "**Pencahayaan**\n",
    "\n",
    "![Pencahayaan](./images/iluminasi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peran MLP untuk Pemrosesan Data Skala Besar\n",
    "\n",
    "> Dengan model yang cukup kompleks dan *hidden layer* yang cukup, seharusnya MLP cukup digunakan tanpa perlu melakukan pemrosesan data lebih lanjut\n",
    "\n",
    "![Question Mark](./images/36601.png)\n",
    "\n",
    "Jawabannya adalah: **Tidak**!\n",
    "\n",
    "Pada faktanya, diketahui bahwa semakin banyak **hidden layer** yang digunakan, hasilnya bisa jadi lebih buruk ketimbang model neural network yang lebih **shallow**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Dua Layer](./images/training_speed_2_layers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tiga Layer](./images/training_speed_3_layers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Empat Layer](./images/training_speed_4_layers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pengamatan**\n",
    "\n",
    "Semakin dalam **hidden layer** dari neural network, gradient semakin kecil dan mengecil ketika melakukan propagasi balik melalui **hidden layer**. Ini artinya, *layer* yang letaknya paling awal akan belajar semakin lambat dibanding neuron yang letaknya paling depan. Fenomena ini dikatakan sebagai masalah **vanishing gradient**.\n",
    "\n",
    "Tapi, jika yang terjadi adalah sebaliknya: justru gradient pada *layer* paling awal sangat besar dibanding *layer* yang letaknya paling depan. Hal ini disebut sebagai **exploding gradient**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efek dari *exploding/vanishing gradient* diantaranya adalah:\n",
    "\n",
    "- Model memiliki nilai loss yang terlalu besar\n",
    "- Hasil yang tidak stabil, dalam setiap epoch akan terjadi perubahan nilai loss yang terlalu besar\n",
    "- Nilai loss dari model NaN\n",
    "\n",
    "Cara mengetahui apakah terjadi *exploding/vanishing gradient* dengan cara berikut:\n",
    "\n",
    "- Cek *bobot/weight* dari model\n",
    "- Nilai error\n",
    "\n",
    "Cara memperbaiki model yang mengalami masalah *exploding/vanishing gradient*:\n",
    "\n",
    "- Gunakan layer yang lebih sedikit\n",
    "- Memperkecil nilai batch\n",
    "- Menggunakan model RNN seperti LSTM\n",
    "- Gradient clipping (https://keras.io/optimizers/)\n",
    "- Menggunakan regularizer (https://keras.io/regularizers/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
